{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Programming NLP \n",
    "We will look at some typical tools for NLP processing in Python. Examples below can be found in https://github.com/pdeitel/PythonForProgrammers. The areas covered are:\n",
    "- nltk https://nltk.org - tagging stemming lemmaization parts of speech (pos)\n",
    "- textblob https://textblob.readthedocs.io/en/dev/  builds on nltk and simplifies\n",
    "- textatistic  http://www.erinhengel.com/software/textatistic/ readability scores \n",
    "- spacy https://spacy.io/ speed optimized and simplified analysis and similarity scoring \n",
    "\n",
    "Examples below will take you through these tools and typical use cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\i080272\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  #need for parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\i080272\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\i080272\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')  #used for sentiment training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\i080272\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textblob \n",
    "Covers a lot of NLP functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (from nltk>=3.1->textblob) (1.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Today is a beautiful day. Tomorrow looks like bad weather.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 =\"Au'jourd hui il fait beau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is a beautiful day. Tomorrow looks like bad weather.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Today is a beautiful day.\"),\n",
       " Sentence(\"Tomorrow looks like bad weather.\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Today', 'is', 'a', 'beautiful', 'day', 'Tomorrow', 'looks', 'like', 'bad', 'weather'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Today', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('Tomorrow', 'NNP'),\n",
       " ('looks', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('bad', 'JJ'),\n",
       " ('weather', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.07500000000000007, subjectivity=0.8333333333333333)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text1, analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.47662917962091056, p_neg=0.5233708203790892)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining readability \n",
    "Shows various readability scores for a corpus of work. Installation notes:\n",
    "- documentation http://www.erinhengel.com/software/textatistic/\n",
    "- use the github repo https://github.com/erinhengel/Textatistic \n",
    "- unpack and python setup.py install \n",
    "- if/when it fails download VSE https://visualstudio.microsoft.com/downloads/ vs build tools 2019 \n",
    "- Will need to reboot\n",
    "Learn about specific measures, for example https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests Probably different install on a Mac. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Textatistic in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: pyhyphen>=2.0.5 in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (from Textatistic) (3.0.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (from pyhyphen>=2.0.5->Textatistic) (1.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\i080272\\appdata\\local\\continuum\\anaconda4\\envs\\pd\\lib\\site-packages (from pyhyphen>=2.0.5->Textatistic) (1.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Textatistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = (Path(r'./data/RomeoAndJuliet.txt').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textatistic import Textatistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_level = Textatistic(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_count': 133715,\n",
       " 'word_count': 29279,\n",
       " 'sent_count': 3403,\n",
       " 'sybl_count': 34830,\n",
       " 'notdalechall_count': 6963,\n",
       " 'polysyblword_count': 906,\n",
       " 'flesch_score': 97.463,\n",
       " 'fleschkincaid_score': 1.803,\n",
       " 'gunningfog_score': 4.679,\n",
       " 'smog_score': 6.077,\n",
       " 'dalechall_score': 7.818}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reading_level.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity checking in documents \n",
    "Spacy is a high performance nlp package \n",
    "- documentation https://spacy.io/\n",
    "- github https://github.com/explosion/spaCy\n",
    "- usually issues with soft dir linking with error like below:\n",
    "Error: Couldn't link model to 'en_core_web_sm'\n",
    "    Creating a symlink in spacy/data failed. Make sure you have the required\n",
    "    permissions and try re-running the command as admin, or use a\n",
    "    virtualenv. You can still import the model as a module and call its\n",
    "    load() method, or create the symlink manually.\n",
    "\n",
    "    C:\\Users\\i080272\\AppData\\Local\\Continuum\\anaconda3\\envs\\pd\\lib\\site-packages\\en_core_web_sm\n",
    "    -->\n",
    "    C:\\Users\\i080272\\AppData\\Local\\Continuum\\anaconda3\\envs\\pd\\lib\\site-packages\\spacy\\data\\en_core_web_sm\n",
    "- See https://github.com/explosion/spaCy/issues/1283 \n",
    "- This also could be a permissions problem and you need to run ananconda prompt as admin then python -m spacy download en \n",
    "\n",
    "Used to compare corpus for similarity of authorship. In the case below comparing Shakespeare and Sir Francis Bacon taken from Deitel which was taken from project Gutenberg... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en #this needs admin right to work steps below are dependent on this being setup right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stackoverflow we learn that 'en' is a symbolic link to another directory so we can just use an explict import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(Path('./data/RomeoAndJuliet.txt').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(Path('./data/EdwardTheSecond.txt').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "#stop_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i080272\\AppData\\Local\\Continuum\\anaconda4\\envs\\pd\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9470151584521619"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
